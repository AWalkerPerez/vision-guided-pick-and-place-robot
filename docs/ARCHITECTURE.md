# System Architecture

This repo implements a **hardware-first** vision-guided pick-and-place pipeline for a 3DOF robot arm using:
- a top-down USB camera
- ArUco marker detection + pose estimation
- Jacobian-based IK control (Damped Least Squares)
- Dynamixel actuation via OpenRB-150
- ROS 2 (Python)

The system is split into small ROS 2 nodes that communicate via topics.

---

## Components (scripts)

The `src/` folder contains:

- `camera_publisher.py` — publishes camera frames
- `aruco_pose.py` — detects markers and publishes per-marker pose topics (`desired_pos_<id>`)
- `marker_tracking.py` — pick-and-place logic / state machine (records targets, then moves)
- `control_dls.py` — IK control (DLS) (Cartesian target → joint targets)
- `hardware_interface.py` — Dynamixel/OpenRB hardware bridge (commands + feedback + safety)
- `cameraCalibration.py` — offline chessboard calibration (creates `calibration.npz`)

---

## ROS 2 nodes and topics

### 1) Camera Publisher (`camera_publisher.py`)
**Role:** Captures frames and publishes them for vision.

- **Publishes**
  - `camera/image` (`sensor_msgs/Image`)

---

### 2) Vision / Marker Pose (`aruco_pose.py`)
**Role:** Detects markers in the camera stream and publishes their relative pose.

- **Subscribes**
  - `camera/image` (`sensor_msgs/Image`)

- **Publishes (dynamic)**
  - `desired_pos_<marker_id>` (`std_msgs/Float32MultiArray`)
  - Example topics: `desired_pos_0`, `desired_pos_1`, `desired_pos_7`, ...

**Calibration dependency**
- Loads camera intrinsics from `calibration.npz` (generated by `cameraCalibration.py`).

**Reference frame convention**
- Marker **ID 0** is used as a **reference**.
- For each detected marker, it computes pose **relative to marker 0** and publishes that.

**Message layout**
Published as `Float32MultiArray` with 6 values:
`[msg.data[0], msg.data[1], msg.data[2], msg.data[3], msg.data[4], msg.data[5]]
= [axis1_mm, axis2_mm, z_mm, roll_deg, pitch_deg, yaw_deg]`

> Note: In the current implementation the first two axes are swapped compared to the comment in-code,
> but downstream nodes treat the first two entries consistently as the “2D target position”.

---

### 3) Task Logic / State Machine (`marker_tracking.py`)
**Role:** Coordinates the autonomous behavior:
- “recording” stage: record desired goal positions
- “moving” stage: track object positions, then pick-and-place

**Dynamic subscription**
- It scans the ROS graph and automatically subscribes to any topic matching:
  - `desired_pos_<id>` or `/desired_pos_<id>`

**Marker ID convention**
- **Even marker IDs** represent **desired goal positions** (recorded during “recording” stage).
- **Odd marker IDs** represent **object markers** (tracked during “moving” stage).
- The logic pairs them like:
  - object marker `X` uses desired goal stored under marker `(X + 1)`

**Subscribes**
- `joint_state` (from hardware interface)
- `desired_pos_<id>` topics (dynamic)

**Publishes**
- `joint_pos`
- `cartesian_pos`
- `gripper_command`

---

### 4) IK Control (`control_dls.py`)
**Role:** Converts Cartesian target motion into joint commands using **Damped Least Squares**.

**Subscribes**
- `joint_state`

**Publishes**
- `joint_pos`
- `cartesian_pos`

---

### 5) Hardware Interface (`hardware_interface.py`)
**Role:** Bridge to the **physical** Dynamixel/OpenRB system:
- publishes joint feedback
- listens for motion / gripper commands
- provides safety topics

**Publishes**
- `/joint_state`
- `/cartesian_pos`
- `/ee_min_max`
- `/emergency_stop`

**Subscribes**
- `/joint_pos`
- `/joint_vel`
- `/joint_cur`
- `/joint_pos_rel`
- `/gripper_command`

> Important: Some nodes use topic names without a leading `/` (e.g. `joint_pos`),
> while the hardware node subscribes to `/joint_pos`.
> If messages don’t flow, standardise names (either always `/topic` or always `topic`)
> or check what’s actually active with `ros2 topic list`.

---

## Data-flow diagram (high level)
```
                ┌───────────────────────┐
                │    camera_publisher   │
                │  (USB/RGB camera node)│
                └───────────┬───────────┘
                            │  /camera/image
                            v
                ┌───────────────────────┐
                │    aruco_detector     │
                │ (detect IDs + pose)   │
                └───────────┬───────────┘
                            │  /aruco/poses   (pose(s) of marker(s) in camera frame)
                            v
                ┌───────────────────────┐
                │   marker_tracking     │
                │ (select target ID,    │
                │  filter/smooth pose,  │
                │  transform to robot)  │
                └───────────┬───────────┘
                            │  /target_pose   (desired end-effector pose in robot/base frame)
                            v
                ┌───────────────────────┐
                │      control_dls      │
                │ (IK / DLS / Jacobian  │
                │  -> joint commands)   │
                └───────────┬───────────┘
                            │  /joint_cmd     (q_des or dq_des)
                            v
                ┌───────────────────────┐
                │   hardware_interface  │
                │ (send to motors, read │
                │  encoders)            │
                └───────┬───────┬───────┘
                        │       │
          /joint_state  │       │  /gripper_cmd
 (q, dq feedback)       │       │  (open/close)
                        │       │
                        v       v
                ┌───────────────────────┐
                │    control_dls uses   │
                │  /joint_state feedback│
                └───────────────────────┘
```
---

## Execution order (typical)

1. `camera_publisher.py`
2. `aruco_pose.py`  (requires `calibration.npz`)
3. `hardware_interface.py` (requires physical robot connection)
4. `control_dls.py` and/or `marker_tracking.py`

---

## Suggested improvements (optional)
- Standardise topic naming (`/joint_pos` vs `joint_pos`) across all scripts.
- Replace `Float32MultiArray` for marker pose with `geometry_msgs/PoseStamped` (clearer + safer).
- Publish transforms (`tf2_ros`) for `camera → base` and marker frames for easier debugging.
